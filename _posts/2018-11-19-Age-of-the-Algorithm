---
layout:     post
title:      Age of the Algorithm
date:       2018-11-19 
summary:    A reading response. 
categories: jekyll
thumbnail: cogs
tags:
 - Blog
---


# "Age of the Algorithm"
"Since human beings have begun to make new things, the connection between creator and creation has been a point of contention. Can works of art exists in a creative vacuum? Or are their meanings always intrinsically linked to their creators intentions? While this conversation normally revolves around art, music, and literature, the digital age has ushered in a new subject, algorithms. Cathy O’Neil, author of Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy, believes that algorithms can be just as flawed as their creators. O’Neil uses a colorful metaphor, about cooking dinner for her family,  to explain this concept: “I curate that data because I don’t really use [certain ingredients] … therefore imposing my agenda on this algorithm. And then I’m also defining success, right? I’m in charge of success. I define success to be if my kids eat vegetables at that meal …. My eight year old would define success to be like whether he got to eat Nutella.” Algorithms are vitally important to our day to day life, but the fact that they are the creations of human beings mean that they cannot be completely separated from the people who create them. We define the parameters of algorithms, giving them purpose, but also bias. To me, this makes me question whether or not it is at all possible to create a purely mathematical algorithm. According to O’Neil, it seems unlikely. However, this idea goes farther than just algorithms. It broadens the conversation around what we can separate ourselves from, and what we cannot. Specifically, it leads me to wonder if artificial intelligence could ever be fully separate from its human creators. It is downright daunting to imagine a super intelligence capable not only of immense computing, but bigotry as well. In reality, I imagine that the biases of thinking machines and algorithms will be (and are) far more subtle than programmed racism, rather, their biases come from the inescapable fact that humans are inherently flawed, and our technologies may never be fully separated from our own inherent biases. This leads to a number of very big, very complicated questions. Is it ethical for us to use the machines we create to think even if they are biased, simply passing the culpability of our actions on to a digital entity?"
